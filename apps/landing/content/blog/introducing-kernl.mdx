---
title: Introducing kernl
slug: introducing-kernl
date: 2025-12-01
author: dremnik
category: product
excerpt: The runtime for software 3.0.
image: kernl
---

Today we're excited to introduce kernl, a TypeScript framework for building agents that remember, reason, and act.

The pitch is simple: agents that work in production, built on infrastructure you can actually understand.

## Why this exists

Building agents looks easy at first. You call the API, parse some JSON, maybe add a tool or two. Then you ship it.

Conversation state fills up context windows. Memory that lasts beyond a single session turns into an infrastructure project—embeddings, vector stores, retrieval logic. Tool execution grows from a simple function call into validation, error handling, retries, approval flows.

You've accidentally built a framework. And it's not a good one.

So you reach for something off the shelf. LangChain. CrewAI. Vercel AI SDK. Mastra. But something's off there too.

85% of production agents are custom code, and these are the three main reasons teams cited for throwing them away after trying them: [1]

1. Dependency hell
"LangChain pulls in 47 packages. Our security team said no."

2. Abstraction mismatch
"We spent more time fighting the framework than solving our problem."

3. Debugging nightmares
"When it breaks, we need to read THEIR code, not ours."

This is the state of things today: roll your own and drown in accidental complexity, or use a framework and fight it until you fork it.

We think there's a third option.

## How we think about this

Software 3.0 needs better infrastructure—that's what we're building.

Aggressive minimalism is at the heart of the design ethos behind this company, and the belief in quality is central to its DNA.

Every line of code, and every addition to the framework is intentional. Ruthless simplification is a never ending war that we will continue to wage.

In practice, this means 3 external dependencies—not 47. Functions you can read in one sitting if you want to browse the source. When something breaks, you trace it in your code, not ours.

It also means you own what you use. Our toolkit [marketplace](/marketplace) works like shadcn: browse, copy, customize. The code lives in your repo, under your control, customizable to your needs.

And lastly it means building in the open. The Linux spirit—code that belongs to everyone, shaped by the people who use it. We want to cultivate a community, not a customer base.

## A couple of our principles

- *Aggressive minimalism*. Like I said, this is our central ethos. Every abstraction earns its place. If it doesn't need to exist, it doesn't.
- *An open world, a strong community*. The AI ecosystem is fragmented. We're building for interoperability, not lock-in. We believe in the power of collective intelligence and decentralization.
- *Composition over inheritance*. Take what you need, leave what you don't.
- *Opinionated, not constricting*. Sensible defaults, escape hatches where you need them.
- *Your environment, your control*. Your agents run where you run them. Not on our servers. Not in someone else's cloud. The execution environment is yours.

These are the ideals that we will strive to live up to, and will continue to cultivate as part of this ecosystem's DNA.

## Getting started

```bash
npm install kernl
```

```ts
import { Kernl, Agent } from "kernl";
import { anthropic } from "@kernl-sdk/ai/anthropic";

const kernl = new Kernl();

const agent = new Agent({
  id: "assistant",
  model: anthropic("claude-sonnet-4-5"),
  instructions: "You are a helpful assistant.",
});

kernl.register(agent);

await agent.run("Hello, world.");
```

Read the [docs](https://docs.kernl.sh). Browse the [marketplace](/marketplace). Or just start building.

---

[1] Qiu et al., "[Measuring Agents in Production](https://arxiv.org/pdf/2512.04123)," 2025.
